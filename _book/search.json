[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"Welcome portfolio. collection different skills projects showcase can done. page contains different group skills stands alone presentation. website work progress.","code":""},{"path":"index.html","id":"about-me","chapter":"Welcome!","heading":"About Me","text":"studied Life sciences university applied sciences Utrecht (HU). Within degree specialized bio-molecular research, bioinformatics data analysis visualization. passionate biology, molecular life sciences data analysis. work environment can combine interests break solve complex problems, allowing apply programming laboratory analysis skills create reliable methods research improve existing ones.","code":""},{"path":"index.html","id":"future-additions","chapter":"Welcome!","heading":"Future additions","text":"near future like add portfolio page information Metatranscriptomics project pages statistical analysis examples (correlation regression analysis example).","code":""},{"path":"directory-organisation.html","id":"directory-organisation","chapter":"Directory organisation","heading":"Directory organisation","text":"working together groups using github alone ones projects great importance keep consistent organized structure easily find data code. one hand crucial avoid confusion version usage (v4_file instead latestlateslatest_file) established files named example README.txt file explanation separate file. hand makes writing code edit, analyse plot data much easier path data files fixed. directory organisation reproducibility allows anyone quickly understand files data contain helps analysts write easier code deepening file locations.short example set type shown . organized one courses guerrilla analytics format better explain structure. easy work much enjoy looking well organized project.Although course organized properly allot missing items like missing code chunks due running code different server changes data Rmarkdown files instead individual scripts. Note also consists 3 projects, just one. means depth comparison single project, depth creates chaos.","code":"fs::dir_tree(here::here(\"daur2/\"))\n\n/home/1686589/daur2/\n├── rna_seq_ipsc\n│   ├── README.txt\n│   ├── code\n│   │   └── Input.R\n│   ├── data\n│   ├── rnaseq_ipsc.Rmd\n│   └── rnaseq_ipsc.html\n├── rnaseq_airway\n│   ├── README.txt\n│   ├── code\n│   │   ├── input.R\n│   │   └── namen.txt\n│   ├── data\n│   │   ├── airway_sampledata.csv\n│   │   ├── bam\n│   │   │   ├── SRR1039508.bam\n│   │   │   ├── SRR1039508.bam.indel.vcf\n│   │   │   ├── SRR1039508.bam.summary\n│   │   │   ├── SRR1039509.bam\n│   │   │   ├── SRR1039509.bam.indel.vcf\n│   │   │   ├── SRR1039509.bam.summary\n│   │   │   ├── SRR1039512.bam\n│   │   │   ├── SRR1039512.bam.indel.vcf\n│   │   │   ├── SRR1039512.bam.summary\n│   │   │   ├── SRR1039513.bam\n│   │   │   ├── SRR1039513.bam.indel.vcf\n│   │   │   ├── SRR1039513.bam.summary\n│   │   │   ├── SRR1039516.bam\n│   │   │   ├── SRR1039516.bam.indel.vcf\n│   │   │   ├── SRR1039516.bam.summary\n│   │   │   ├── SRR1039517.bam\n│   │   │   ├── SRR1039517.bam.indel.vcf\n│   │   │   ├── SRR1039517.bam.summary\n│   │   │   ├── SRR1039520.bam\n│   │   │   ├── SRR1039520.bam.indel.vcf\n│   │   │   ├── SRR1039520.bam.summary\n│   │   │   ├── SRR1039521.bam\n│   │   │   ├── SRR1039521.bam.indel.vcf\n│   │   │   ├── SRR1039521.bam.summary\n│   │   │   └── alignment_statistics.rds\n│   │   ├── counts\n│   │   │   └── read_counts.rds\n│   │   ├── fastq\n│   │   │   ├── SRR1039508_1.fastq.gz\n│   │   │   ├── SRR1039508_2.fastq.gz\n│   │   │   ├── SRR1039509_1.fastq.gz\n│   │   │   ├── SRR1039509_2.fastq.gz\n│   │   │   ├── SRR1039512_1.fastq.gz\n│   │   │   ├── SRR1039512_2.fastq.gz\n│   │   │   ├── SRR1039513.fastq.gz\n│   │   │   ├── SRR1039513_1.fastq.gz\n│   │   │   ├── SRR1039513_2.fastq.gz\n│   │   │   ├── SRR1039516.fastq.gz\n│   │   │   ├── SRR1039516_1.fastq.gz\n│   │   │   ├── SRR1039516_2.fastq.gz\n│   │   │   ├── SRR1039517_1.fastq.gz\n│   │   │   ├── SRR1039517_2.fastq.gz\n│   │   │   ├── SRR1039520.fastq.gz\n│   │   │   ├── SRR1039520_1.fastq.gz\n│   │   │   ├── SRR1039520_2.fastq.gz\n│   │   │   ├── SRR1039521.fastq.gz\n│   │   │   ├── SRR1039521_1.fastq.gz\n│   │   │   ├── SRR1039521_2.fastq.gz\n│   │   │   ├── fastq_dump_downloader.sh\n│   │   │   ├── fastqc.sh\n│   │   │   └── refgenome_downloader.sh\n│   │   ├── fastqc_output\n│   │   │   ├── SRR1039508_1_fastqc.html\n│   │   │   ├── SRR1039508_1_fastqc.zip\n│   │   │   ├── SRR1039508_2_fastqc.html\n│   │   │   ├── SRR1039508_2_fastqc.zip\n│   │   │   ├── SRR1039509_1_fastqc.html\n│   │   │   ├── SRR1039509_1_fastqc.zip\n│   │   │   ├── SRR1039509_2_fastqc.html\n│   │   │   ├── SRR1039509_2_fastqc.zip\n│   │   │   ├── SRR1039512_1_fastqc.html\n│   │   │   ├── SRR1039512_1_fastqc.zip\n│   │   │   ├── SRR1039512_2_fastqc.html\n│   │   │   ├── SRR1039512_2_fastqc.zip\n│   │   │   ├── SRR1039513_1_fastqc.html\n│   │   │   ├── SRR1039513_1_fastqc.zip\n│   │   │   ├── SRR1039513_2_fastqc.html\n│   │   │   ├── SRR1039513_2_fastqc.zip\n│   │   │   ├── SRR1039513_fastqc.html\n│   │   │   ├── SRR1039513_fastqc.zip\n│   │   │   ├── SRR1039516_1_fastqc.html\n│   │   │   ├── SRR1039516_1_fastqc.zip\n│   │   │   ├── SRR1039516_2_fastqc.html\n│   │   │   ├── SRR1039516_2_fastqc.zip\n│   │   │   ├── SRR1039516_fastqc.html\n│   │   │   ├── SRR1039516_fastqc.zip\n│   │   │   ├── SRR1039517_1_fastqc.html\n│   │   │   ├── SRR1039517_1_fastqc.zip\n│   │   │   ├── SRR1039517_2_fastqc.html\n│   │   │   ├── SRR1039517_2_fastqc.zip\n│   │   │   ├── SRR1039520_1_fastqc.html\n│   │   │   ├── SRR1039520_1_fastqc.zip\n│   │   │   ├── SRR1039520_2_fastqc.html\n│   │   │   ├── SRR1039520_2_fastqc.zip\n│   │   │   ├── SRR1039520_fastqc.html\n│   │   │   ├── SRR1039520_fastqc.zip\n│   │   │   ├── SRR1039521_1_fastqc.html\n│   │   │   ├── SRR1039521_1_fastqc.zip\n│   │   │   ├── SRR1039521_2_fastqc.html\n│   │   │   ├── SRR1039521_2_fastqc.zip\n│   │   │   ├── SRR1039521_fastqc.html\n│   │   │   └── SRR1039521_fastqc.zip\n│   │   ├── hg38_genome\n│   │   │   └── GRCh38.primary_assembly.genome.fa\n│   │   └── hg38_index\n│   │       ├── hg38_index.00.b.array\n│   │       ├── hg38_index.00.b.tab\n│   │       ├── hg38_index.files\n│   │       ├── hg38_index.log\n│   │       ├── hg38_index.reads\n│   │       ├── subread-index-sam-186134-meVx1N\n│   │       └── subread-index-sam-193622-AYN0aX\n│   ├── rna_seq.Rmd\n│   └── rna_seq.html\n└── rnaseq_onecut\n    ├── README.txt\n    ├── Rmarkdown\n    │   ├── rnaseq_eind.Rmd\n    │   ├── rnaseq_eind.html\n    │   ├── rnaseq_eind.log\n    │   ├── rnaseq_eind.tex\n    │   ├── v1_Eindopdracht.Rmd\n    │   └── v2_Eindopdracht.Rmd\n    ├── code\n    ├── data\n    └── output\n        ├── 6_volcano_plot-1.png\n        ├── perbase_SRR7866699.png\n        └── perseq_SRR7866699.png"},{"path":"relational-databases.html","id":"relational-databases","chapter":"Relational Databases","heading":"Relational Databases","text":"Working relational databases means many cases communicate using SQL. pull store data important follows small demonstration can done.first start loading required data short analysis. use data gapminder data set, part dslabs package. additionally merge data set two data sets added complexity (flu_data & dengue_data).\nloading data need process make easier work R. also make allot easier work compare data load DBeaver using SQL.finish section plot simple graph show bit gapminder data set. chose display GDP according World Bankdev. (gapminder data set) selection countries Europe 1960 2016.","code":"\n############ Load in Data ##############################################\n## Gapminder data from the dslabs package\n  gapdat <- gapminder\n  gapdata_tidy <- gapminder\n## Dengue en flu data \n  dengue_data <- read_csv(here::here(\"data/dengue_data.csv\"), skip = 10)\n  flu_data <- read_csv(here::here(\"data/flu_data.csv\"), skip = 10)\n########################################################################\n############################## Tidy Data ################################\n\n## Gapminder data looks very tidy so no changes there except for the year column, that needs to become Date\n  gapdata_tidy$year <- as.character(gapdata_tidy$year)\n  colnames(gapdat) <- c(\"country\", \"Date\", \"infant_mortality\", \"life_expectancy\", \"fertility\", \"population\", \"gdp\", \"continent\", \"region\")\n\n## flu data tidy:\n  flu_data_tidy <- flu_data %>% pivot_longer(cols = -c(Date),\n                                             names_to = \"country\",\n                                             values_to = \"count_cases\") \n  ## dengue data tidy:\n  dengue_data_tidy <- dengue_data %>% pivot_longer(cols = -c(Date),\n                                             names_to = \"country\",\n                                             values_to = \"values\") \n########################### Export the Data ############################\n\n## Now we are going to write off the tidy data sets as csv and rds to export them later into the database\n  write_csv(gapdat_tidy, path = here::here(\"data/gapdat_tidy.csv\"))\n  write_csv(flu_data_tidy, path = here::here(\"data/flu_tidy.csv\"))\n  write_csv(dengue_data_tidy, path = here::here(\"data/dengue_tidy.csv\"))\n  \n  write_rds(gapdat_tidy, path = here::here(\"data/gapdat_tidy.rds\"))\n  write_rds(flu_data_tidy, path = here::here(\"data/flu_tidy.rds\"))\n  write_rds(dengue_data_tidy, path = here::here(\"data/dengue_tidy.rds\"))\n\n  -- In DBeaver we now make a new database to store the data\nCREATE DATABASE fludata;\n\n-- Next we connect to the database in Rstudio (not visible)-- Then in SQL we define the primary keys of the tables (Date and country)\nalter table public.flu_data \n    add constraint PK_flu_data primary key (Date, country);\n    \nalter table public.dengue_data \n    add constraint PK_dengue_data primary key (Date, country);\n\nalter table public.gapminer_data \n    add constraint PK_gapminder_data primary key (Date, country);\n\n-- And we inspect the data from the table flu_data to check if all went well\nselect * from flu_data;\n######################## Inspect the Data ######################################\n## Now that the data has been stored in the database we can inspect it in R using the connection made\n\n# Shows the tables\ndbListTables(con)\n\n# Shows the table of gaminder_data\ndbGetQuery(con, 'SELECT * FROM gapminder_data')\n####################### Merge the gapminder data ##############################\n# Next we want to join the 3 data frames together based on the year and country columns\n## flu data tidy:\n  flu_data_tidy <- flu_data_tidy %>% separate(col = Date, into = c(\"year\", \"Month\", \"Day\"), sep = \"-\", remove = FALSE)\n\n## dengue data tidy:\n  dengue_data_tidy <- dengue_data_tidy  %>% separate(col = Date, into = c(\"year\", \"Month\", \"Day\"), sep =\"-\", remove = FALSE)\n\n## Now we can add them together like glue\nglue <- dengue_data_tidy %>% full_join(flu_data_tidy, by=c(\"year\",\"country\", \"Day\", \"Month\", \"Date\"))\n\n## fix year variable\ngapdata_tidy$year <- as.integer(gapdata_tidy$year)\nglue$year <- as.integer(glue$year)\n\n## Fully merge the data sets\nmerged_dat <- glue %>% full_join(gapdata_tidy, by=c(\"country\", \"year\"))\n\n## inspect new data set\n#merged_dat\n#################### Graphs #####################################################\n\n# Now we have a dataframe with the data from all the 3 tables and we can make some exploratory graphs with it, I opted for a simple graph to compare the countries GDP's\n\n## Graph showing the decline in infant mortality in bolivia\ngdp_graph_europe <- gapdata_tidy %>% filter(region == \"Western Europe\") %>% \n  select(country, year, gdp, continent) %>%\n  group_by(gdp) \n\ngdp_graph_europe %>% ggplot(aes(x = year, y = gdp, colour = country)) +\n  theme_classic() +\n  scale_color_paletteer_d(\"awtools::a_palette\") +\n  geom_line() +\n  scale_x_continuous(breaks = round(seq(min(gdp_graph_europe$year), max(gdp_graph_europe$year), by = 10),1)) + \n  labs(title = \"GDP of Western-European countries from 1960 to 2016\",\n       y= \"GDP\",\n       x= \"Time (year)\")"},{"path":"parameters.html","id":"parameters","chapter":"Parameters","heading":"Parameters","text":"page look use parameters Rmarkdown. end use data European Center Disease Control COVID-19 case data. goal create two separate graphs, one showing COVID-19 related cases specified month year country COVID-19 related deaths specified month year country. make parameters customisable month, year country graphs supposed show.Parameters defined yaml header Rmarkdown documents can used just like variable code. One great advantage can customized fly change function output. case defined three parameters:can change date combinations want country long data input data code work. makes work -though wrote function code custom input function complete Rmarkdown file. handy indeed.page show code can take look parameters used . can find parameters used variables: params$parameter_nameParameters great work save time want change small things code already used . personally prefer writing good functions reusing parameters great tool apply aswell.","code":"\n###################### Load in the Data ########################################\n\n## First lets load in the Data kindly supplied by the ECDC. \n  data <- read_csv(here::here(\"data/covid_data.csv\"))\n\n######################## Data wrangling ########################################\n## Now we are going to change the date data type to date instead of chr.\n  data$dateRep <- as.Date(data$dateRep, \"%d/%m/%Y\")\n\n############################# Graphs ###########################################\n\n## Because the data is already tidy enough we don't need to wrangle further and can simply start plotting the graphs we want.\n  \n# Graph #1, the amount of covid-19 cases in a selected country for a selected period of time\n  data %>% select(month, year, day, cases, countriesAndTerritories, dateRep) %>% \n    filter(dateRep >= as.Date(params$date_from) & dateRep <= as.Date(params$date_until), countriesAndTerritories %in% c(params$country)) %>%\n    ggplot(aes(x=dateRep, y=cases)) + \n    geom_line(aes(color = countriesAndTerritories)) +\n    labs(title= paste(\"Covid-19 Cases in\", params$country),\n         subtitle = paste(params$date_from, params$date_until),\n         x= \"Date\",\n         y= \"Number of Cases\") +\n    scale_color_manual(values=c(\"turquoise3\")) +\n    theme_classic()\n\n# Graph #2, The amount of covid-19 Deaths in a selected country for a selected period of time. If I didn't work with parameters I would have build a function for these two graphs seeing as they are very similar in code. \n  data %>% select(month, year, day, deaths, countriesAndTerritories, dateRep) %>% \n    filter(dateRep >= as.Date(params$date_from) & dateRep <= as.Date(params$date_until), countriesAndTerritories %in% c(params$country)) %>%\n    ggplot(aes(x=dateRep, y=deaths)) + \n    geom_line(aes(color = countriesAndTerritories)) +\n    labs(title= paste(\"Covid-19 Deaths in\", params$country),\n         subtitle = paste(params$date_from, params$date_until),\n         x= \"Date\",\n         y= \"Number of Deaths\") +\n    scale_color_manual(values=\"turquoise4\") +\n    theme_classic()"},{"path":"noldus-project.html","id":"noldus-project","chapter":"Noldus project","heading":"Noldus project","text":"Noldus Inc. (“Noldus | Advance Behavioral Research” (n.d.)) University Applied sciences Utrecht (HU) worked team 5 create shiny application help analyse data acquired one research products: Erasmus Ladder. Erasmus Ladder setup consists horizontal ladder determine differences behavior mice recording steps made selection sensors. Variations amount steps made type steps made mice can recorded accurately allows statistical analysis determine differences groups.","code":""},{"path":"noldus-project.html","id":"the-output","chapter":"Noldus project","heading":"The output","text":"application analyses data acquired Erasmus Ladder plots exploratory publication ready graphs together statistical analysis researchers easily interpret results. One challenges creating application figuring kind data interesting researchers. reading articles using device speaking researchers field made selection publication ready graph functions read data formatted Erasmus ladder. also made selection exploratory graphs meant help researches get overview data showing basic information like amount mice used, different groups mice, etc. graphs portray overview things like different types steps mice made different groups.","code":""},{"path":"noldus-project.html","id":"literature-references","chapter":"Noldus project","heading":"Literature References","text":"examples data interesting research purposes looked selection different articles. us important criteria articles use Erasmus ladder mostly interested interpreted data . type graphs used portrayed data important us base decisions graphs want application produce based input data. One first graphs found interesting provides clear visual variances steps made different groups mice (María Fernanda Vinueza Veloz et al. 2015). graph shows two different groups mice, one Purkinje cell deficiency (Pcd) one control group make runs crossing Erasmus ladder. step recorded type steps determined based distance traveled. page 3517 (Fig. 3) article can observe difference variation steps used might caused due Purkinje cell deficiency.\nVersions step type graphs plotted session can also found research (Sathyanesan Gallo 2019; Sathyanesan et al. 2018). graphs depict decrease variation steps used control groups time. might caused mice learning cross bridge efficiently. different type graph looked reaction mice different ques guide mice device. research (M. F. Vinueza Veloz et al. 2012) gave us fresh look data helped guide decisions data might seen relevant.also looked types cerebellum research (Schonewille et al. 2011) selected data better answer research questions. Although mostly applicable project give insight different data variables important different research groups.\nUsing Erasmus ladder ’s difficult first glance show effects cerebellum degradation. One starts recognize ’s change patterns new patterns switch pattern chaotic portray inputs.","code":""},{"path":"noldus-project.html","id":"the-application","chapter":"Noldus project","heading":"The application","text":"Sadly can’t show application code application. Although quite proud managed create, ’s prototype application changed updated now integrated software owned us. hope able give justice description .","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""},{"path":"references.html","id":"pages","chapter":"References","heading":"404 pages","text":"default, users directed 404 page try access webpage found.","code":""},{"path":"references.html","id":"references-1","chapter":"References","heading":"References","text":"","code":""}]
